# fÃ¼ge das oben in deine spinne.py ein um die verbindung zu aktivieren
from scanner import revolte_gegen_geschwafel, zÃ¼nd_das_warnlicht

def verarbeite_agb(url):
    agb_link = suche_agb_link(url) # deine spinne sucht den link
    if agb_link:
        text = requests.get(agb_link).text # die spinne holt den inhalt
        
        # jetzt wird es welluminÃ¶s:
        print("ğŸ” starte automatische prÃ¼fung...")
        
        # wir prÃ¼fen auf gesappel
        revolte_gegen_geschwafel(text) 
        
        # hier simulieren wir die punktzahl - wenn es zu viel ist:
        # zÃ¼nd_das_warnlicht("automatischer fund") 
    else:
        print("nichts gefunden das system bleibt ruhig")


import requests
from bs4 import BeautifulSoup # das ist wie eine lupe fÃ¼r die spinne

def suche_agb_link(start_url):
    print(f"ğŸ•µï¸ suche nach der nadel im heuhaufen auf: {start_url}")
    try:
        r = requests.get(start_url)
        suppe = BeautifulSoup(r.text, 'html.parser')
        
        # die spinne schaut sich alle links (<a> tags) an
        for link in suppe.find_all('a'):
            text = str(link.string).lower()
            # fÃ¤hrte aufnehmen:
            if 'agb' in text or 'nutzung' in text or 'bedingungen' in text:
                ziel = link.get('href')
                print(f"ğŸ¯ fÃ¤hrte gefunden: {text} -> {ziel}")
                return ziel
    except Exception as e:
        print(f"âš ï¸ fehler beim suchen: {e}")
    return None

# test: suche_agb_link("https://www.beispielseite.de")

# deine persÃ¶nliche "futter-liste"
ziel_seiten = [
    "https://www.google.de",
    "https://www.instagram.com",
    "https://www.paypal.com"
]

def starte_groÃŸreinemachen():
    for seite in ziel_seiten:
        print(f"\n--- ğŸ§º nÃ¤chste seite wird welluminiert: {seite} ---")
        verarbeite_agb(seite)

# mit diesem befehl schickst du sie los:
# starte_groÃŸreinemachen()

# Deine erweiterten SchlagwÃ¶rter fÃ¼r die FÃ¤hrte
SCHLAGWOERTER = ['agb', 'nutzung', 'bedingungen', 'vertrag', 'kaufvertrag', 'richtlinie']

def suche_agb_link(start_url):
    print(f"ğŸ•µï¸ Tiefen-Scan startet auf: {start_url}")
    try:
        r = requests.get(start_url)
        suppe = BeautifulSoup(r.text, 'html.parser')
        
        for link in suppe.find_all('a'):
            # Wir machen den Text klein, damit wir alles finden
            link_text = str(link.string).lower()
            href = link.get('href')
            
            # Die Spinne prÃ¼ft jetzt auf deine neuen SchlagwÃ¶rter
            if any(wort in link_text for wort in SCHLAGWOERTER):
                print(f"ğŸ¯ Treffer im Versteck gefunden: {link_text} -> {href}")
                return href
    except Exception as e:
        print(f"âš ï¸ Fehler im Unterholz: {e}")
    return None

def tiefe_wuehl_tour(url, aktuelle_tiefe=0, max_tiefe=2):
    # bremse damit wir nicht das ganze internet scannen
    if aktuelle_tiefe > max_tiefe:
        return

    # 1. fÃ¤hrte aufnehmen
    link = suche_agb_link(url)
    if link:
        # 2. direkt verarbeiten (ernten und prÃ¼fen)
        verarbeite_agb(link)
        
        # 3. jetzt gehen wir eine ebene tiefer
        # die spinne schaut ob auf der neuen seite noch mehr vertrÃ¤ge lauern
        tiefe_wuehl_tour(link, aktuelle_tiefe + 1, max_tiefe)

# ganz oben in deine spinne.py
ergebnis_liste = []

def verarbeite_agb(url):
    agb_link = suche_agb_link(url)
    if agb_link:
        text = requests.get(agb_link).text
        # wir holen uns den score vom scanner (simuliert)
        score = 8 # hier wÃ¼rde dein scanner-wert stehen
        
        status = "ğŸ”´ GEFAHR" if score >= 8 else "ğŸŸ¢ OK"
        ergebnis_liste.append(f"{status} | Seite: {url}")
        
        if score >= 8:
            zÃ¼nd_das_warnlicht(f"Dreck gefunden auf {url}")

def zeige_bericht():
    print("\n--- ğŸ“‹ DER WELLUMINÃ–SE ABSCHLUSS-BERICHT ---")
    for eintrag in ergebnis_liste:
        print(eintrag)
    print("--- ALLES DURCHGEWÃœHLT ---")
